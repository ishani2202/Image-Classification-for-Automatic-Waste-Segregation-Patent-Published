{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishani2202/RiverClean/blob/main/DL_train_Capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSq9UljddGcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2097af-40fa-4c7e-8ed7-3fdb753c21e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "6\n",
            "3\n",
            "0\n",
            "3\n",
            "5\n",
            "4\n",
            "3\n",
            "3\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import  Model, load_model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # images from google drive\n",
        "PATH=\"/content/drive/My Drive/dataset-resized/dataset-resized\"\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')\n",
        "batch_size = 512\n",
        "epochs = 10\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')\n",
        "\n",
        "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=test_dir,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "# base_model = tf.keras.applications.InceptionV3(include_top=False,\n",
        "#     weights=\"imagenet\",\n",
        "#     input_shape=(150, 150, 3))\n",
        "# base_model.trainable = False\n",
        "# X = base_model.output\n",
        "# X = Flatten(input_shape=base_model.output_shape[1:])(X)\n",
        "# X = Dense(256, activation='relu')(X)\n",
        "# X = Dropout(0.5)(X)\n",
        "# Output = Dense(7, activation='softmax')(X)\n",
        "# inception= Model(inputs=base_model.input, outputs=Output)\n",
        "\n",
        "# inception.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#           optimizer=optimizers.Adam(lr = 0.001),\n",
        "#           metrics=['accuracy'])\n",
        "\n",
        "# history = inception.fit_generator(\n",
        "#     train_data_gen,\n",
        "#     epochs=epochs,\n",
        "#     validation_data = val_data_gen)\n",
        "\n",
        "# inception.save('/content/drive/My Drive/dataset-resized/training_inception_hdf5_format/trainedModel.h5')\n",
        "\n",
        " base_model = tf.keras.applications.ResNet50V2(include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(150, 150, 3))    # pre-trained model,    loads weights pretrained on imagenet\n",
        "\n",
        "# setup for resnet training from here\n",
        "\n",
        "base_model.trainable = False\n",
        "X = base_model.output\n",
        "X = Flatten(input_shape=base_model.output_shape[1:])(X)\n",
        "X = Dense(256, activation='relu')(X)  #Rectified Linear Units\n",
        "X = Dropout(0.5)(X)\n",
        "Output = Dense(7, activation='softmax')(X)\n",
        "resnet= Model(inputs=base_model.input, outputs=Output)\n",
        "\n",
        "resnet.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          optimizer=optimizers.Adam(lr = 0.001),\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "history = resnet.fit_generator(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data = val_data_gen)\n",
        "\n",
        "\n",
        "resnet.save('/content/drive/My Drive/dataset-resized/training_resnet_hdf5_format/trainedModelRN.h5')\n",
        "# resnet model saved\n",
        "\n",
        "\n",
        "# testing\n",
        "import numpy\n",
        "for imagePath in  test_data_gen[0][0]:\n",
        "  # print( str(imagePath))\n",
        "  imagePath=np.expand_dims(imagePath,axis=0)\n",
        "  prediction = resnet.predict(imagePath)\n",
        "  print(numpy.argmax(prediction))\n",
        "  # 0 = bio\n",
        "  # 1 = cardboard\n",
        "  # 2 = glass\n",
        "  # 3 = metal\n",
        "  # 4 = paper\n",
        "  # 5 = plastic\n",
        "  # 6 = trash"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')  # images from google drive\n",
        "PATH=\"/content/drive/My Drive/dataset-resized/dataset-resized\"\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')\n",
        "batch_size = 512\n",
        "epochs = 10\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')\n",
        "\n",
        "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=test_dir,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "import numpy\n",
        "for imagePath in  test_data_gen[0][0]:\n",
        "  # print( str(imagePath))\n",
        "  imagePath=np.expand_dims(imagePath,axis=0)\n",
        "  prediction = resnet.predict(imagePath)\n",
        "  print(numpy.argmax(prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woncBB3f3URe",
        "outputId": "7498223b-6fc1-42f3-be62-22c15a104df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 9553 images belonging to 7 classes.\n",
            "Found 688 images belonging to 7 classes.\n",
            "Found 10 images belonging to 1 classes.\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "6\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0gAGk9KdJy9",
        "outputId": "fb201ea6-67ae-4296-a350-889e9c5d6d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn6V6IRDdedY"
      },
      "outputs": [],
      "source": [
        "PATH=\"/content/drive/My Drive/dataset-resized/dataset-resized\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3xiShr9eQWA"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-q-Z2KoeXsQ"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3L8c9hbeZ1r"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "epochs = 10  #changed from 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4KTxJQCebw9"
      },
      "outputs": [],
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jj94sshedf8",
        "outputId": "4c823ea9-f1e9-4d91-9bd3-1eb0cbb79f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9554 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1OQ3C7jefRq",
        "outputId": "ad2f2e83-d471-4f24-b3a8-a1ef9d344bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 688 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')\n",
        "\n",
        "# checkpoint_path = \"/content/drive/My Drive/dataset-resized/training_inception/\"\n",
        "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                                                  save_weights_only=True,\n",
        "#                                                  verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gENr2tUs_9PX",
        "outputId": "3766eca2-62fa-4af1-cc8c-b9ec4c7e2acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=test_dir,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "-VWlXfJNKSZU",
        "outputId": "8fe09bfe-b896-4f5c-d791-47577ea75f02"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e0480d739773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(tf.__version__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(tf.keras.__version__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
          ]
        }
      ],
      "source": [
        "# print(tf.__version__)\n",
        "# print(tf.keras.__version__)\n",
        "print(python.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEkUyG-AeijE",
        "outputId": "76c89e5f-13a2-45dd-ad03-a17141ba92f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "19/19 [==============================] - 2186s 114s/step - loss: 7.3665 - accuracy: 0.4078 - val_loss: 1.1547 - val_accuracy: 0.6003\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 466s 25s/step - loss: 1.1185 - accuracy: 0.5943 - val_loss: 0.9117 - val_accuracy: 0.6773\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 479s 25s/step - loss: 0.9609 - accuracy: 0.6480 - val_loss: 0.8424 - val_accuracy: 0.7267\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 464s 24s/step - loss: 0.8641 - accuracy: 0.6874 - val_loss: 0.7207 - val_accuracy: 0.7500\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 462s 25s/step - loss: 0.8019 - accuracy: 0.7136 - val_loss: 0.6582 - val_accuracy: 0.7674\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 469s 25s/step - loss: 0.7570 - accuracy: 0.7270 - val_loss: 0.5987 - val_accuracy: 0.7892\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 502s 27s/step - loss: 0.7033 - accuracy: 0.7462 - val_loss: 0.5768 - val_accuracy: 0.7994\n",
            "Epoch 8/10\n",
            " 6/19 [========>.....................] - ETA: 5:20 - loss: 0.6878 - accuracy: 0.7574"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.InceptionV3(include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(150, 150, 3))\n",
        "base_model.trainable = False\n",
        "X = base_model.output\n",
        "X = Flatten(input_shape=base_model.output_shape[1:])(X)\n",
        "X = Dense(256, activation='relu')(X)\n",
        "X = Dropout(0.5)(X)\n",
        "Output = Dense(7, activation='softmax')(X)\n",
        "inception= Model(inputs=base_model.input, outputs=Output)\n",
        "\n",
        "inception.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          optimizer=optimizers.Adam(lr = 0.001),\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "history = inception.fit_generator(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data = val_data_gen)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_Rukq1g7e-g"
      },
      "outputs": [],
      "source": [
        "\n",
        "# inception.save('/content/drive/My Drive/dataset-resized/training_inception/')\n",
        "resnet = tf.keras.models.load_model('/content/drive/MyDrive/dataset-resized/training_resnet_hdf5_format/trainedModelRN.h5')\n",
        "# resnet.summary()\n",
        "InceptionNet = tf.keras.models.load_model('/content/drive/MyDrive/dataset-resized/training_inception_hdf5_format/trainedModel.h5')\n",
        "# InceptionNet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    from sklearn.metrics import classification_report, confusion_matrix\n",
        "    resnet.confusion_matrix()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "QrFLfBMIoSNJ",
        "outputId": "0ca1e71f-62d5-4171-adc8-7af0d257be08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-859fbfaff5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'confusion_matrix'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBu3UFBV9JKG"
      },
      "outputs": [],
      "source": [
        "inception.save('/content/drive/My Drive/dataset-resized/training_inception_hdf5_format/trainedModel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6v-QvsDG4iI"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"/content/drive/My Drive/dataset-resized/training_resnet/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm2a4V3uel44",
        "outputId": "85768fad-1c9b-4a5b-c405-96f9e6c6850a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "19/19 [==============================] - 1935s 100s/step - loss: 6.3487 - accuracy: 0.4894 - val_loss: 1.0390 - val_accuracy: 0.6119\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 729s 38s/step - loss: 1.0676 - accuracy: 0.6018 - val_loss: 0.7390 - val_accuracy: 0.7267\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 727s 38s/step - loss: 0.8258 - accuracy: 0.7000 - val_loss: 0.5585 - val_accuracy: 0.8110\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 726s 38s/step - loss: 0.6826 - accuracy: 0.7575 - val_loss: 0.4572 - val_accuracy: 0.8328\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 727s 38s/step - loss: 0.5968 - accuracy: 0.7795 - val_loss: 0.3928 - val_accuracy: 0.8547\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 725s 38s/step - loss: 0.5054 - accuracy: 0.8127 - val_loss: 0.3198 - val_accuracy: 0.8968\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 727s 38s/step - loss: 0.4526 - accuracy: 0.8308 - val_loss: 0.2643 - val_accuracy: 0.9215\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 729s 38s/step - loss: 0.3968 - accuracy: 0.8446 - val_loss: 0.2173 - val_accuracy: 0.9244\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 730s 38s/step - loss: 0.3598 - accuracy: 0.8627 - val_loss: 0.1957 - val_accuracy: 0.9317\n",
            "Epoch 10/10\n",
            "11/19 [================>.............] - ETA: 4:38 - loss: 0.3106 - accuracy: 0.8747"
          ]
        }
      ],
      "source": [
        " base_model = tf.keras.applications.ResNet50V2(include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(150, 150, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "X = base_model.output\n",
        "X = Flatten(input_shape=base_model.output_shape[1:])(X)\n",
        "X = Dense(256, activation='relu')(X)\n",
        "X = Dropout(0.5)(X)\n",
        "Output = Dense(7, activation='softmax')(X)\n",
        "resnet= Model(inputs=base_model.input, outputs=Output)\n",
        "\n",
        "resnet.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          optimizer=optimizers.Adam(lr = 0.001),\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "history = resnet.fit_generator(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data = val_data_gen)\n",
        "\n",
        "resnet.save('/content/drive/My Drive/dataset-resized/training_resnet/')\n",
        "\n",
        "resnet.save('/content/drive/My Drive/dataset-resized/training_resnet_hdf5_format/trainedModelRN.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "P6MfimTpnQpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puk5CaRAdRxC",
        "outputId": "0c1dad28-d008-4c35-f0c5-1b5cd662670d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "2OGHkl8Uv73D",
        "outputId": "78074d35-b3be-4809-eddc-42163be7bf10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and Validation Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1,11)\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs, acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "FvrpUpSTkQM7",
        "outputId": "d0eb738b-b6ae-4f8a-8674-60fda99481dc"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-a58c935f9cb2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    plot_model(inception, to_file='model_plot.png', show_shapes=True, show_layer_names=False,expand_nested=False\u001b[0m\n\u001b[0m                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(inception, to_file='model_plot.png', show_shapes=True, show_layer_names=False,expand_nested=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_WGUS1slHZY",
        "outputId": "96b17a54-1ef7-49ad-af79-d965e91bbde4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: classify in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from classify) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7->classify) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install classify\n",
        "import classify\n",
        "import base64\n",
        "import argparse\n",
        "import operator\n",
        "import warnings\n",
        "# import RPi.GPIO as GPIO\n",
        "import time\n",
        "# import pygame\n",
        "# import pygame.camera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "mDkS3aDisFcM",
        "outputId": "1a998fd2-d905-40d8-ee49-ad64de310e4f"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0c730fdc654f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimagePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/dataset-resized/dataset-resized/test/trash137.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'predict_classes'"
          ]
        }
      ],
      "source": [
        "imagePath = '/content/drive/My Drive/dataset-resized/dataset-resized/test/trash137.jpg'\n",
        "result = classify.analyse(imagePath)\n",
        "val=max(result.items(), key=operator.itemgetter(1))[0]\n",
        "print(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54fNZ0idyygX"
      },
      "outputs": [],
      "source": [
        "#from gpiozero import Servo\n",
        "import RPi.GPIO as GPIO\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "import os\n",
        "import numpy as np\n",
        "PATH=\"/home/pi\"\n",
        "test_dir = os.path.join(PATH, 'test_img_store')\n",
        "batch_size = 512\n",
        "epochs = 10  #changed from 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "resnet = tf.keras.models.load_model('/home/pi/projects/training_resnet_hdf5_format/trainedModelRN.h5')\n",
        "import pygame\n",
        "import pygame.camera\n",
        "width = 1920\n",
        "height = 1080\n",
        "pygame.init()\n",
        "pygame.camera.init()\n",
        "camlist = pygame.camera.list_cameras()\n",
        "cam = pygame.camera.Camera(camlist[0],(width,height))\n",
        "\n",
        "while true:\n",
        "  cam.start()\n",
        "  image = cam.get_image()\n",
        "  time.sleep(2)\n",
        "  cam.stop()\n",
        "  pygame.image.save(image,'/home/pi/test_img_store/images_dir/image.jpg')\n",
        "  test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size, directory=test_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), class_mode='categorical')\n",
        "  # imagePath = '/home/pi/test_img_store/images_dir/image.jpg'\n",
        "  imagePath = test_data_gen[0][0][0]\n",
        "  imagePath=np.expand_dims(imagePath,axis=0)\n",
        "  prediction = resnet.predict(imagePath)\n",
        "  # 0 = bio\n",
        "  # 1 = cardboard\n",
        "  # 2 = glass\n",
        "  # 3 = metal\n",
        "  # 4 = paper\n",
        "  # 5 = plastic\n",
        "  # 6 = trash\n",
        "  if np.argmax(prediction)== 4 or np.argmax(prediction)== 1 or np.argmax(prediction)== 0:\n",
        "    print('biodegradable')\n",
        "    GPIO.setmode(GPIO.BCM)  # set up BCM GPIO numbering\n",
        "    servo = 18\n",
        "    GPIO.setup(servo, GPIO.OUT)\n",
        "    p=GPIO.PWM(servo,50)\n",
        "    p.start(7.5)\n",
        "    time.sleep(1)\n",
        "    p.ChangeDutyCycle(10.5) #right\n",
        "    time.sleep(5)\n",
        "    p.ChangeDutyCycle(7.5)    #center\n",
        "    time.sleep(1)\n",
        "  else:\n",
        "    GPIO.setmode(GPIO.BCM)  # set up BCM GPIO numbering\n",
        "    servo = 18\n",
        "    GPIO.setup(servo, GPIO.OUT)\n",
        "    p=GPIO.PWM(servo,50)\n",
        "    p.start(7.5)    #center\n",
        "    time.sleep(1)\n",
        "    p.ChangeDutyCycle(4.5)  #left\n",
        "    time.sleep(5)\n",
        "    p.ChangeDutyCycle(7.5)    #center\n",
        "    time.sleep(1)\n",
        "    print('Non-biodegradable')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZZgzSHJIlf1U",
        "outputId": "0966546d-14b8-4d7e-85f8-2adfaf24409b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.8.0'"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u87L38MIlhjr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from gpiozero import Servo\n",
        "import RPi.GPIO as GPIO\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "PATH=\"/home/pi\"\n",
        "test_dir = os.path.join(PATH, 'test_img_store')\n",
        "\n",
        "batch_size = 512\n",
        "epochs = 10  #changed from 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "resnet = tf.keras.models.load_model('/home/pi/projects/training_resnet_hdf5_format/trainedModelRN.h5')\n",
        "\n",
        "\n",
        "\n",
        "import pygame\n",
        "import pygame.camera\n",
        "\n",
        "width = 1920\n",
        "height = 1080\n",
        "\n",
        "pygame.init()\n",
        "pygame.camera.init()\n",
        "camlist = pygame.camera.list_cameras()\n",
        "cam = pygame.camera.Camera(camlist[0],(width,height))\n",
        "\n",
        "nn = int(1)\n",
        "while true:\n",
        "  cam.start()\n",
        "  image = cam.get_image()\n",
        "  time.sleep(2)\n",
        "  cam.stop()\n",
        "  pygame.image.save(image,'/home/pi/test_img_store/images_dir/image.jpg')\n",
        "  test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size, directory=test_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), class_mode='categorical')\n",
        "  # imagePath = '/home/pi/test_img_store/images_dir/image.jpg'\n",
        "  imagePath = test_data_gen[0][0][0]\n",
        "  imagePath=np.expand_dims(imagePath,axis=0)\n",
        "  prediction = resnet.predict(imagePath)\n",
        "  #print(np.argmax(prediction))\n",
        "  # 6 = trash\n",
        "  # 5 = plastic\n",
        "  # 0 = bio\n",
        "  # 1 = cardboard\n",
        "  # 4 = paper\n",
        "  # 3 = metal\n",
        "  # 2 = glass\n",
        "  if np.argmax(prediction)== 4 or np.argmax(prediction)== 1 or np.argmax(prediction)== 0:\n",
        "    print('biodegradable')\n",
        "    GPIO.setmode(GPIO.BCM)  # set up BCM GPIO numbering\n",
        "    servo = 18\n",
        "    GPIO.setup(servo, GPIO.OUT)\n",
        "    p=GPIO.PWM(servo,50)\n",
        "    p.start(7.5)\n",
        "    print(1)\n",
        "    time.sleep(1)\n",
        "    p.ChangeDutyCycle(10.5)\n",
        "    time.sleep(5)\n",
        "    p.ChangeDutyCycle(7.5)\n",
        "    time.sleep(1)\n",
        "  else:\n",
        "    GPIO.setmode(GPIO.BCM)  # set up BCM GPIO numbering\n",
        "    servo = 18\n",
        "    GPIO.setup(servo, GPIO.OUT)\n",
        "    p=GPIO.PWM(servo,50)\n",
        "    p.start(7.5)\n",
        "\n",
        "    print(0)\n",
        "    time.sleep(1)\n",
        "    p.ChangeDutyCycle(4.5)\n",
        "    time.sleep(5)\n",
        "    p.ChangeDutyCycle(7.5)\n",
        "    time.sleep(1)\n",
        "    print('Non-biodegradable')"
      ],
      "metadata": {
        "id": "bLc3R_P8P4oE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}